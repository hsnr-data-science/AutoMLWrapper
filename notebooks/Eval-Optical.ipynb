{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "533c1d68-10c2-42c6-8594-29d5d993ee90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 12:45:22.434803: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-11 12:45:22.479640: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-11 12:45:23.271072: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')] Physical GPUs, [LogicalDevice(name='/device:GPU:0', device_type='GPU')] Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 12:45:25.101015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46000 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:3b:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "TENSORFLOW = 1\n",
    "GLUON = 1\n",
    "\n",
    "import os  \n",
    "if GLUON:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "if TENSORFLOW:\n",
    "    import tensorflow as tf\n",
    "\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "            tf.config.set_logical_device_configuration(\n",
    "                gpus[0],\n",
    "                [tf.config.LogicalDeviceConfiguration(memory_limit=46000)])\n",
    "            logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "            print(gpus, \"Physical GPUs,\", logical_gpus, \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1063b58-ae43-4b82-8b13-dd1d66da9f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n",
      "WARNING AutoSklearn could not be mported. It might not b available in this environment. Err: \n",
      " No module named 'autosklearn'.\n",
      "WARNING AutoSklearn could not be imported. It might not be available in this environment. Err: \n",
      " No module named 'autosklearn'.\n"
     ]
    }
   ],
   "source": [
    "import warnings, pandas as pd, requests, mlflow, sys, os, logging, numpy as np\n",
    "from automlwrapper import AutoMLWrapper, SedarDataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sedarapi import SedarAPI\n",
    "\n",
    "logging.getLogger('automlwrapper').setLevel(logging.ERROR)\n",
    "\n",
    "np.random.seed(1313)\n",
    "\n",
    "TIME_LIMIT = 60 * 15\n",
    "AUTOKERAS_TRAILS = 20\n",
    "AUTOKERAS_EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85666f08-70b7-4a27-9d5f-3adbd1d3da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_MLFLOW = False\n",
    "\n",
    "MLFLOW_URI = 'http://192.168.220.107:6798'\n",
    "MLFLOW_EXPID = '1'\n",
    "if USE_MLFLOW:\n",
    "    mlflow.set_tracking_uri(MLFLOW_URI) \n",
    "    mlflow.set_experiment(experiment_id=MLFLOW_EXPID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "336e9d03-3566-4333-be2b-48ef75557614",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEDAR_URI = 'http://192.168.220.107:5000'\n",
    "\n",
    "SEDAR = SedarAPI(SEDAR_URI)\n",
    "DataLoader = SedarDataLoader(SEDAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3cd65f3-4749-42ff-8931-2377a84efd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_location = './tmp/data/opticalv1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b7e16a-2eb7-4bee-99dd-d23207f616d4",
   "metadata": {},
   "source": [
    "# download data to the above location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad70e56a-8c78-4278-8076-cbbecf2cc56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  823M  100  823M    0     0  89.4M      0  0:00:09  0:00:09 --:--:-- 93.2M\n"
     ]
    }
   ],
   "source": [
    "!curl --create-dirs -O --output-dir \\\n",
    "./tmp/data/opticalv1 \\\n",
    "https://gitlab.com/mibbels/automlwrapperdata/-/raw/main/image-classification/surface_defects_image_classification.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e70f8c8-5ee7-43bf-9470-d8027206649e",
   "metadata": {},
   "source": [
    "## Read the image classification dataset from files\n",
    "#### Same code utilizing the SEDAR API:\n",
    "```python\n",
    "DataLoader.query_data('<workspace id>',\n",
    "                      '<dataset id>',\n",
    "                      file_save_location = zip_location)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45bc1109-92e1-490d-b231-9b8bf1c7e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optical, class_map = DataLoader.classificationAsDataFrame(zip_location, zip_location + '/unzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c488142-511a-4820-b0ac-09d9534e6647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_few_shot(df, num_shots = 10, target_column = 'label'):\n",
    "\n",
    "    few_shot_df = pd.DataFrame()\n",
    "    \n",
    "    for label in df[target_column].unique():\n",
    "        sampled_df = df[df[target_column] == label].sample(\n",
    "            n=min(\n",
    "                num_shots,\n",
    "                len(df[df[target_column] == label])\n",
    "            ),\n",
    "            replace=False\n",
    "        )\n",
    "        few_shot_df = pd.concat([few_shot_df, sampled_df])\n",
    "\n",
    "    return few_shot_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322f494a-3ee1-43f6-a942-9074fb6b517b",
   "metadata": {},
   "source": [
    "# create artificial few-shot datasets @ 5 and @ 20 shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff686365-5d1f-43d2-a6fc-c12793a28c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = optical.drop(columns=['label'])  \n",
    "y = optical['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "train_few5 = create_few_shot(train, 5, 'label')\n",
    "#test_few5 = optical[~optical.index.isin(train_few5.index)]\n",
    "\n",
    "train_few20 = create_few_shot(train, 20, 'label')\n",
    "#test_few20 = optical[~optical.index.isin(train_few20.index)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9069f3aa-6b73-4ff5-8a0a-00a88d740de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image    20\n",
       "label    20\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_few5.count()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ceee9d91-334a-4070-9e0f-0b9921b17aeb",
   "metadata": {},
   "source": [
    "train_few5.count()\n",
    "\n",
    "image    20\n",
    "label    20\n",
    "dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5819ba7e-450a-4242-a86e-0721a6b9ceb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image    80\n",
       "label    80\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_few20.count()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e3c5f442-0853-4b46-87a7-b5790647a8c2",
   "metadata": {},
   "source": [
    "image    80\n",
    "label    80\n",
    "dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae2b3e9b-1714-4554-8e1f-718a2b636432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image    79\n",
       "label    79\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.count()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "36e0d4c2-28a1-4a18-a6a1-6251cfdd27f1",
   "metadata": {},
   "source": [
    "image    79\n",
    "label    79\n",
    "dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bea2f82-a9be-4ba0-adda-49bcb63fe312",
   "metadata": {},
   "source": [
    "# Optimizing a single predictor using AutoGluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab88acd2-c6d0-4eda-a252-bdccb80b4857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper_gluon(train_data, eval_metric):\n",
    "    \n",
    "    wrapper = AutoMLWrapper('autogluon')\n",
    "    wrapper.AllowExtraHyperparameters({'fit': ['hyperparameters'],\n",
    "                                       'constructor': ['num_classes']})\n",
    "    wrapper.Train(\n",
    "        train_data=train_data,\n",
    "        target_column='label',\n",
    "        task_type='classification',\n",
    "        data_type='image',\n",
    "        problem_type='multiclass',\n",
    "        hyperparameters={\n",
    "            'time_limit': TIME_LIMIT,\n",
    "            'preset' : 'medium_quality',\n",
    "            'eval_metric' : eval_metric,\n",
    "            'validation_metric':eval_metric,\n",
    "            'verbosity':1,\n",
    "                            }    # comment out if extra parameters below\n",
    "            #####\n",
    "            #    Extra parameter were specified. The wrapper will now accept them.\n",
    "            # Parameters not present in 'AllowExtraHyperparameters' or the .yaml \n",
    "            # file are still ignored.\n",
    "            #####\n",
    "            #'hyperparameters':{\"optimization.max_epochs\": epochs},\n",
    "            #'num_classes':4\n",
    "            #          }     # uncomment if extra parameters \n",
    "            \n",
    "    )\n",
    "    \n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de9737c-b1d8-4c58-b094-4c991542b3fa",
   "metadata": {},
   "source": [
    "### @5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84571e7e-b9aa-4b52-a95e-4ade73d34a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "w_med5 = wrapper_gluon(train_few5, 'f1_macro')\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2a8bc706-efa9-44cc-baa0-773c2a51909a",
   "metadata": {},
   "source": [
    " | Name              | Type                            | Params\n",
    "----------------------------------------------------------------------\n",
    "0 | model             | TimmAutoModelForImagePrediction | 4.2 M \n",
    "1 | validation_metric | MulticlassF1Score               | 0     \n",
    "2 | loss_func         | CrossEntropyLoss                | 0     \n",
    "----------------------------------------------------------------------\n",
    "4.2 M     Trainable params\n",
    "0         Non-trainable params\n",
    "4.2 M     Total params\n",
    "16.829    Total estimated model params size (MB)\n",
    "\n",
    "/usr/local/automl/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:281: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
    "  rank_zero_warn(\n",
    "\n",
    "Epoch 9: 100%\n",
    "2/2 [00:01<00:00, 1.68it/s]\n",
    "\n",
    "Epoch 0, global step 1: 'val_f1_macro' reached 0.12500 (best 0.12500), saving model to '/home/jovyan/AutoMLOutput/autogluon1712648202.079422/epoch=0-step=1.ckpt' as top 3\n",
    "\n",
    "Epoch 1, global step 2: 'val_f1_macro' reached 0.12500 (best 0.12500), saving model to '/home/jovyan/AutoMLOutput/autogluon1712648202.079422/epoch=1-step=2.ckpt' as top 3\n",
    "\n",
    "Epoch 2, global step 3: 'val_f1_macro' reached 0.33333 (best 0.33333), saving model to '/home/jovyan/AutoMLOutput/autogluon1712648202.079422/epoch=2-step=3.ckpt' as top 3\n",
    "\n",
    "Epoch 3, global step 4: 'val_f1_macro' reached 0.37500 (best 0.37500), saving model to '/home/jovyan/AutoMLOutput/autogluon1712648202.079422/epoch=3-step=4.ckpt' as top 3\n",
    "\n",
    "Epoch 4, global step 5: 'val_f1_macro' reached 0.66667 (best 0.66667), saving model to '/home/jovyan/AutoMLOutput/autogluon1712648202.079422/epoch=4-step=5.ckpt' as top 3\n",
    "\n",
    "Epoch 5, global step 6: 'val_f1_macro' reached 0.66667 (best 0.66667), saving model to '/home/jovyan/AutoMLOutput/autogluon1712648202.079422/epoch=5-step=6.ckpt' as top 3\n",
    "\n",
    "Epoch 6, global step 7: 'val_f1_macro' reached 0.66667 (best 0.66667), saving model to '/home/jovyan/AutoMLOutput/autogluon1712648202.079422/epoch=6-step=7.ckpt' as top 3\n",
    "\n",
    "Epoch 7, global step 8: 'val_f1_macro' was not in top 3\n",
    "\n",
    "Epoch 8, global step 9: 'val_f1_macro' was not in top 3\n",
    "\n",
    "Epoch 9, global step 10: 'val_f1_macro' was not in top 3\n",
    "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
    "\n",
    "Predicting DataLoader 0: 100%\n",
    "1/1 [00:00<00:00, 37.91it/s]\n",
    "Predicting DataLoader 0: 100%\n",
    "1/1 [00:00<00:00, 35.38it/s]\n",
    "Predicting DataLoader 0: 100%\n",
    "1/1 [00:00<00:00, 33.10it/s]\n",
    "\n",
    "CPU times: user 21.7 s, sys: 4.26 s, total: 26 s\n",
    "Wall time: 22.9 s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337e98f8-4ee9-40c7-9f47-bacba5c1b65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "re5 = w_med5.Evaluate(test, target_column=None)#, **kwargs)\n",
    "print(re5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dc50b9de-33c1-41e3-b461-ffae61e1958e",
   "metadata": {},
   "source": [
    "Predicting DataLoader 0: 100%\n",
    "3/3 [00:00<00:00, 3.92it/s]\n",
    "\n",
    "{'f1_macro': 0.617722199811752}\n",
    "CPU times: user 354 ms, sys: 297 ms, total: 652 ms\n",
    "Wall time: 2.68 s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b20e22-b11e-4dbc-979a-56fa57a70550",
   "metadata": {},
   "source": [
    "### @20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032df6c9-66c8-4b97-85f1-d1f2a9a71a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "w_med20 = wrapper_gluon(train_few20, 'f1_macro')\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "317c047e-d237-4914-91f2-38ebbfa115fa",
   "metadata": {},
   "source": [
    " | Name              | Type                            | Params\n",
    "----------------------------------------------------------------------\n",
    "0 | model             | TimmAutoModelForImagePrediction | 4.2 M \n",
    "1 | validation_metric | MulticlassF1Score               | 0     \n",
    "2 | loss_func         | CrossEntropyLoss                | 0     \n",
    "----------------------------------------------------------------------\n",
    "4.2 M     Trainable params\n",
    "0         Non-trainable params\n",
    "4.2 M     Total params\n",
    "16.829    Total estimated model params size (MB)\n",
    "\n",
    "/usr/local/automl/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:281: PossibleUserWarning: The number of training batches (8) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
    "  rank_zero_warn(\n",
    "\n",
    "Epoch 4: 50%\n",
    "4/8 [00:01<00:01, 3.32it/s]\n",
    "\n",
    "Epoch 0, global step 1: 'val_f1_macro' reached 0.33036 (best 0.33036), saving model to '/home/jovyan/AutoMLOutput/autogluon1712648227.648736/epoch=0-step=1.ckpt' as top 3\n",
    "\n",
    "Epoch 1, global step 2: 'val_f1_macro' reached 0.86667 (best 0.86667), saving model to '/home/jovyan/AutoMLOutput/autogluon1712648227.648736/epoch=1-step=2.ckpt' as top 3\n",
    "\n",
    "Epoch 2, global step 3: 'val_f1_macro' reached 0.93651 (best 0.93651), saving model to '/home/jovyan/AutoMLOutput/autogluon1712648227.648736/epoch=2-step=3.ckpt' as top 3\n",
    "\n",
    "Epoch 3, global step 4: 'val_f1_macro' reached 0.93651 (best 0.93651), saving model to '/home/jovyan/AutoMLOutput/autogluon1712648227.648736/epoch=3-step=4.ckpt' as top 3\n",
    "\n",
    "Predicting DataLoader 0: 100%\n",
    "1/1 [00:00<00:00, 8.50it/s]\n",
    "Predicting DataLoader 0: 100%\n",
    "1/1 [00:00<00:00, 40.14it/s]\n",
    "Predicting DataLoader 0: 100%\n",
    "1/1 [00:00<00:00, 36.91it/s]\n",
    "\n",
    "CPU times: user 19.9 s, sys: 2.17 s, total: 22.1 s\n",
    "Wall time: 18.8 s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e658a33c-9ac3-4732-8a23-26ca802f1d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "re20 = w_med20.Evaluate(test, target_column=None)#, **kwargs)\n",
    "print(re20)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2129ccd2-f4db-448e-a688-b0d3a0eb6277",
   "metadata": {},
   "source": [
    "Predicting DataLoader 0: 100%\n",
    "3/3 [00:00<00:00, 4.94it/s]\n",
    "\n",
    "{'f1_macro': 0.8482858604809824}\n",
    "CPU times: user 131 ms, sys: 234 ms, total: 365 ms\n",
    "Wall time: 2.34 s\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858d7fc6-fb8b-427d-9f17-6c34b4b7b44e",
   "metadata": {},
   "source": [
    "# Neural network optimization using the Wrapper with AutoKeras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8d472b-07c6-45c7-878f-6d3b7575d9cf",
   "metadata": {},
   "source": [
    "- you need to specify the batch size manually for 5-shot , default exceeds 20 samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39264212-8370-4ad7-aa00-3e7c5f06fb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper_keras(train_data, epochs, trials, eval_metric, batch):\n",
    "    import keras_tuner \n",
    "\n",
    "    wrapper = AutoMLWrapper('autokeras')\n",
    "    wrapper.AllowExtraHyperparameters({'fit':['batch_size']})\n",
    "    wrapper.Train(\n",
    "        train_data=train_data,\n",
    "        target_column='label',\n",
    "        task_type='classification',\n",
    "        data_type='image',\n",
    "        problem_type='multiclass',\n",
    "        hyperparameters={\n",
    "            'evaluation_metric':[eval_metric, 'acc', 'AUC', 'Precision', 'Recall'],\n",
    "            'epochs':epochs,\n",
    "            'num_trials':trials,\n",
    "            'objective_metric':keras_tuner.Objective(\"val_f1_score\", direction=\"max\"),\n",
    "            'batch_size':batch\n",
    "        }\n",
    "    )\n",
    "    if USE_MLFLOW:\n",
    "         additional_tags = {\n",
    "         \"workspace\":\"DefaultWorkspace,13b4787c3e454649aa05a4cd680edc37\",\n",
    "         \"notebook\": \"glass classifiaction PB,854c94fd-1898-4f03-b0c6-b60b5571b102\",\n",
    "         \"is_public\":\"true\",\n",
    "         \"datasets\":\"glass_schema|986f2e837ca44f3e8c0ee7d2dc0c4287\",\n",
    "         \"username\":\"mibbels\",\n",
    "         }\n",
    "         n = 2\n",
    "         wrapper.MlflowUploadTopN(n, additional_tags)\n",
    "        \n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8034b8-fa87-4540-9cda-183504e4b598",
   "metadata": {},
   "source": [
    "### @5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6b127e-93ca-4739-8844-37ceaf51767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "f1 = tf.keras.metrics.F1Score(\n",
    "        average='macro', threshold=None, name='f1_score', dtype=None\n",
    "    )\n",
    "\n",
    "n_epoch = AUTOKERAS_EPOCHS\n",
    "n_trial = AUTOKERAS_TRAILS\n",
    "w_keras = wrapper_keras(train_few5, n_epoch, n_trial, f1, batch=8)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf9a5554-723b-4083-bc67-7dd1f5ca5c46",
   "metadata": {},
   "source": [
    "Trial 20 Complete [00h 00m 43s]\n",
    "\n",
    "Best val_f1_score So Far: 0.25\n",
    "Total elapsed time: 00h 12m 05s\n",
    "Epoch 1/30\n",
    "\n",
    "2024-04-09 07:58:22.975025: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
    "\n",
    "3/3 [==============================] - 3s 759ms/step - loss: 1231.7705 - f1_score: 0.1909 - acc: 0.2500 - auc: 0.4725 - precision: 0.1538 - recall: 0.1000\n",
    "Epoch 2/30\n",
    "3/3 [==============================] - 1s 222ms/step - loss: 107.4550 - f1_score: 0.6162 - acc: 0.7000 - auc: 0.8000 - precision: 0.7000 - recall: 0.7000\n",
    "Epoch 3/30\n",
    "3/3 [==============================] - 1s 212ms/step - loss: 184.6959 - f1_score: 0.3333 - acc: 0.5000 - auc: 0.6667 - precision: 0.5000 - recall: 0.5000        \n",
    "Epoch 4/30\n",
    "3/3 [==============================] - 1s 210ms/step - loss: 137.6097 - f1_score: 0.5018 - acc: 0.6000 - auc: 0.7333 - precision: 0.6000 - recall: 0.6000        \n",
    "Epoch 5/30\n",
    "3/3 [==============================] - 1s 207ms/step - loss: 32.3500 - f1_score: 0.6667 - acc: 0.7500 - auc: 0.8333 - precision: 0.7500 - recall: 0.7500\n",
    "Epoch 6/30\n",
    "3/3 [==============================] - 1s 205ms/step - loss: 0.0000e+00 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 7/30\n",
    "3/3 [==============================] - 1s 206ms/step - loss: 2.5451e-06 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 8/30\n",
    "3/3 [==============================] - 1s 204ms/step - loss: 10.1078 - f1_score: 0.5417 - acc: 0.6000 - auc: 0.7333 - precision: 0.6000 - recall: 0.6000\n",
    "Epoch 9/30\n",
    "3/3 [==============================] - 1s 204ms/step - loss: 3.5190 - f1_score: 0.8352 - acc: 0.8500 - auc: 0.9000 - precision: 0.8500 - recall: 0.8500\n",
    "Epoch 10/30\n",
    "3/3 [==============================] - 1s 202ms/step - loss: 0.0000e+00 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 11/30\n",
    "3/3 [==============================] - 1s 202ms/step - loss: 1.8482 - f1_score: 0.7619 - acc: 0.8000 - auc: 0.9217 - precision: 0.8000 - recall: 0.8000\n",
    "Epoch 12/30\n",
    "3/3 [==============================] - 1s 203ms/step - loss: 6.2334e-04 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 13/30\n",
    "3/3 [==============================] - 1s 202ms/step - loss: 0.1422 - f1_score: 0.9495 - acc: 0.9500 - auc: 0.9992 - precision: 0.9500 - recall: 0.9500\n",
    "Epoch 14/30\n",
    "3/3 [==============================] - 1s 201ms/step - loss: 0.0000e+00 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 15/30\n",
    "3/3 [==============================] - 1s 201ms/step - loss: 0.0000e+00 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 16/30\n",
    "3/3 [==============================] - 1s 202ms/step - loss: 0.0000e+00 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 17/30\n",
    "3/3 [==============================] - 1s 201ms/step - loss: 0.0000e+00 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 18/30\n",
    "3/3 [==============================] - 1s 209ms/step - loss: 0.0000e+00 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 19/30\n",
    "3/3 [==============================] - 1s 201ms/step - loss: 0.0000e+00 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 20/30\n",
    "3/3 [==============================] - 1s 201ms/step - loss: 0.0000e+00 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 21/30\n",
    "3/3 [==============================] - 1s 202ms/step - loss: 0.0000e+00 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 22/30\n",
    "3/3 [==============================] - 1s 202ms/step - loss: 0.0000e+00 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 23/30\n",
    "3/3 [==============================] - 1s 202ms/step - loss: 0.0000e+00 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 24/30\n",
    "3/3 [==============================] - 1s 202ms/step - loss: 0.0000e+00 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 25/30\n",
    "3/3 [==============================] - 1s 199ms/step - loss: 0.0000e+00 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 26/30\n",
    "3/3 [==============================] - 1s 201ms/step - loss: 0.0000e+00 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 27/30\n",
    "3/3 [==============================] - 1s 201ms/step - loss: 0.0000e+00 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 28/30\n",
    "3/3 [==============================] - 1s 202ms/step - loss: 0.0000e+00 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 29/30\n",
    "3/3 [==============================] - 1s 202ms/step - loss: 0.0000e+00 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 30/30\n",
    "3/3 [==============================] - 1s 202ms/step - loss: 0.0000e+00 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "INFO:tensorflow:Assets written to: /home/jovyan/AutoMLOutput/autokeras1712648771.325166/image_classifier/best_model/assets\n",
    "\n",
    "INFO:tensorflow:Assets written to: /home/jovyan/AutoMLOutput/autokeras1712648771.325166/image_classifier/best_model/assets\n",
    "\n",
    "CPU times: user 11min 21s, sys: 2min 16s, total: 13min 38s\n",
    "Wall time: 12min 37s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba552d7-93d3-481c-bda1-115e53a33b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "re = w_keras.Evaluate(test, target_column='label', return_dict = True)\n",
    "print(re)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc5b1749-5b42-4344-acf7-7fe442ee6ab2",
   "metadata": {},
   "source": [
    "Not enough memory, reduce batch size to 16.\n",
    "5/5 [==============================] - 4s 463ms/step - loss: 53.2503 - f1_score: 0.5974 - acc: 0.4051 - auc: 0.6034 - precision: 0.4051 - recall: 0.4051\n",
    "{'loss': 53.250328063964844, 'f1_score': 0.5974025726318359, 'acc': 0.40506330132484436, 'auc': 0.6033755540847778, 'precision': 0.40506330132484436, 'recall': 0.40506330132484436}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a36361-014b-47f7-93c7-dc08abae8c32",
   "metadata": {},
   "source": [
    "### @20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57df549c-2e46-4377-a30d-3c43bd28410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "f1 = tf.keras.metrics.F1Score(\n",
    "        average='macro', threshold=None, name='f1_score', dtype=None\n",
    "    )\n",
    "\n",
    "n_epoch = AUTOKERAS_EPOCHS\n",
    "n_trial = AUTOKERAS_TRAILS\n",
    "w_keras = wrapper_keras(train_few20, n_epoch, n_trial, f1, batch=16)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b46575ef-6bf3-4d5c-88e2-287811c9c7ab",
   "metadata": {},
   "source": [
    "Trial 20 Complete [00h 01m 33s]\n",
    "val_f1_score: 0.25\n",
    "\n",
    "Best val_f1_score So Far: 0.25\n",
    "Total elapsed time: 00h 30m 03s\n",
    "Epoch 1/30\n",
    "\n",
    "2024-04-11 10:40:47.689122: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
    "\n",
    "5/5 [==============================] - 4s 569ms/step - loss: 1777.6989 - f1_score: 0.2155 - acc: 0.1125 - auc: 0.3837 - precision: 0.0625 - recall: 0.0500\n",
    "Epoch 2/30\n",
    "5/5 [==============================] - 3s 538ms/step - loss: 80.1783 - f1_score: 0.6667 - acc: 0.7500 - auc: 0.8323 - precision: 0.7500 - recall: 0.7500\n",
    "Epoch 3/30\n",
    "5/5 [==============================] - 3s 517ms/step - loss: 85.5239 - f1_score: 0.6667 - acc: 0.7500 - auc: 0.8333 - precision: 0.7500 - recall: 0.7500      \n",
    "Epoch 4/30\n",
    "5/5 [==============================] - 3s 508ms/step - loss: 40.7690 - f1_score: 0.2745 - acc: 0.3875 - auc: 0.6006 - precision: 0.3875 - recall: 0.3875    \n",
    "Epoch 5/30\n",
    "5/5 [==============================] - 3s 499ms/step - loss: 20.0033 - f1_score: 0.3737 - acc: 0.5000 - auc: 0.6510 - precision: 0.5128 - recall: 0.5000\n",
    "Epoch 6/30\n",
    "5/5 [==============================] - 3s 498ms/step - loss: 3.0600 - f1_score: 0.5414 - acc: 0.6250 - auc: 0.7574 - precision: 0.6250 - recall: 0.6250\n",
    "Epoch 7/30\n",
    "5/5 [==============================] - 2s 497ms/step - loss: 0.9378 - f1_score: 0.6481 - acc: 0.7250 - auc: 0.9174 - precision: 0.7436 - recall: 0.7250\n",
    "Epoch 8/30\n",
    "5/5 [==============================] - 2s 497ms/step - loss: 1.1805 - f1_score: 0.5018 - acc: 0.5875 - auc: 0.8752 - precision: 0.7667 - recall: 0.5750\n",
    "Epoch 9/30\n",
    "5/5 [==============================] - 3s 504ms/step - loss: 0.6113 - f1_score: 0.6032 - acc: 0.6875 - auc: 0.9295 - precision: 0.8852 - recall: 0.6750\n",
    "Epoch 10/30\n",
    "5/5 [==============================] - 3s 497ms/step - loss: 0.3454 - f1_score: 0.6667 - acc: 0.7500 - auc: 0.9789 - precision: 0.8333 - recall: 0.7500\n",
    "Epoch 11/30\n",
    "5/5 [==============================] - 2s 496ms/step - loss: 0.2492 - f1_score: 0.6667 - acc: 0.7500 - auc: 0.9792 - precision: 0.7595 - recall: 0.7500\n",
    "Epoch 12/30\n",
    "5/5 [==============================] - 2s 497ms/step - loss: 0.1837 - f1_score: 0.8667 - acc: 0.8750 - auc: 0.9875 - precision: 0.8831 - recall: 0.8500\n",
    "Epoch 13/30\n",
    "5/5 [==============================] - 3s 499ms/step - loss: 0.1173 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 14/30\n",
    "5/5 [==============================] - 3s 498ms/step - loss: 0.0766 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 15/30\n",
    "5/5 [==============================] - 2s 497ms/step - loss: 0.0456 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 16/30\n",
    "5/5 [==============================] - 3s 498ms/step - loss: 0.0255 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 17/30\n",
    "5/5 [==============================] - 3s 498ms/step - loss: 0.0135 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 18/30\n",
    "5/5 [==============================] - 3s 499ms/step - loss: 0.0070 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 19/30\n",
    "5/5 [==============================] - 3s 499ms/step - loss: 0.0043 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 20/30\n",
    "5/5 [==============================] - 3s 499ms/step - loss: 0.0025 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 21/30\n",
    "5/5 [==============================] - 2s 498ms/step - loss: 0.0015 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 22/30\n",
    "5/5 [==============================] - 2s 498ms/step - loss: 9.5781e-04 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 23/30\n",
    "5/5 [==============================] - 2s 498ms/step - loss: 6.6025e-04 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 24/30\n",
    "5/5 [==============================] - 3s 507ms/step - loss: 4.9715e-04 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 25/30\n",
    "5/5 [==============================] - 2s 497ms/step - loss: 3.7093e-04 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 26/30\n",
    "5/5 [==============================] - 3s 500ms/step - loss: 2.8490e-04 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 27/30\n",
    "5/5 [==============================] - 3s 499ms/step - loss: 2.5507e-04 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 28/30\n",
    "5/5 [==============================] - 3s 498ms/step - loss: 2.1166e-04 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 29/30\n",
    "5/5 [==============================] - 2s 498ms/step - loss: 1.8781e-04 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "Epoch 30/30\n",
    "5/5 [==============================] - 3s 498ms/step - loss: 1.7332e-04 - f1_score: 1.0000 - acc: 1.0000 - auc: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
    "INFO:tensorflow:Assets written to: /home/jovyan/AutoMLOutput/autokeras1712830234.145286/image_classifier/best_model/assets\n",
    "\n",
    "INFO:tensorflow:Assets written to: /home/jovyan/AutoMLOutput/autokeras1712830234.145286/image_classifier/best_model/assets\n",
    "\n",
    "CPU times: user 29min 2s, sys: 4min 58s, total: 34min 1s\n",
    "Wall time: 31min 33s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc7a328-7e9d-42fb-9143-f430354e9d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "re = w_keras.Evaluate(test, target_column='label', return_dict = True)\n",
    "print(re)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b42c132f-94bc-4eb8-96c1-6366adb70232",
   "metadata": {},
   "source": [
    "3/3 [==============================] - 6s 892ms/step - loss: 3.4813 - f1_score: 0.6015 - acc: 0.4304 - auc: 0.6762 - precision: 0.4304 - recall: 0.4304\n",
    "{'loss': 3.4812560081481934, 'f1_score': 0.6015267372131348, 'acc': 0.4303797483444214, 'auc': 0.6762272119522095, 'precision': 0.4303797483444214, 'recall': 0.4303797483444214}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7308ab6-f9c8-4e6f-8f82-0c90139b38dc",
   "metadata": {},
   "source": [
    "# Optimizing a few-shot predictor using AutoGluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb8d3ea-97a8-45de-8134-b00e3fd0c7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper_few(train_data, eval_metric):\n",
    "\n",
    "    wrapper = AutoMLWrapper('autogluon')\n",
    "    wrapper.Train(\n",
    "        train_data=train_data,\n",
    "        target_column='label',\n",
    "        task_type='few-shot-classification',\n",
    "        data_type='image',\n",
    "        problem_type='multiclass',\n",
    "        hyperparameters={\n",
    "            'time_limit': TIME_LIMIT,\n",
    "            'preset' : 'best_quality',\n",
    "            'eval_metric' : eval_metric,\n",
    "            'validation_metric':eval_metric,\n",
    "            'verbosity':1,\n",
    "            }\n",
    "    )\n",
    "    \n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c7e729-f907-4e12-ad30-ac737d79319a",
   "metadata": {},
   "source": [
    "### @5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902bd232-104b-4f4a-99d2-dcbdb350d1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "w_few5 = wrapper_few(train_few5, 'f1_macro')\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e9fd9b44-c39e-4e51-beec-23bde3a9d284",
   "metadata": {},
   "source": [
    "Global seed set to 0\n",
    "\n",
    "Predicting DataLoader 0: 100%\n",
    "20/20 [00:00<00:00, 36.35it/s]\n",
    "\n",
    "CPU times: user 26.8 s, sys: 8.98 s, total: 35.8 s\n",
    "Wall time: 15.9 s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2305597b-3c82-480a-867f-cb1014083ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "re5 = w_few5.Evaluate(test, target_column=None)\n",
    "print(re5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f8f0367d-6f04-4425-a858-7fbaae23eb98",
   "metadata": {},
   "source": [
    "Predicting DataLoader 0: 100%\n",
    "79/79 [00:02<00:00, 38.32it/s]\n",
    "\n",
    "{'f1_macro': 0.8687638427464008}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3455b3-558a-4d53-8f02-6ba9187311da",
   "metadata": {},
   "source": [
    "### @20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d01f1e-9c74-4827-b885-387510f2ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "w_few20 = wrapper_few(train_few20, 'f1_macro')\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a639102-e1e6-4291-8968-e8f4f21a0ff1",
   "metadata": {},
   "source": [
    "Predicting DataLoader 0: 100%\n",
    "80/80 [00:02<00:00, 36.22it/s]\n",
    "\n",
    "CPU times: user 27 s, sys: 10.7 s, total: 37.7 s\n",
    "Wall time: 18.1 s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d90701-7757-4fb1-9396-f7bef00c1ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "re5 = w_few20.Evaluate(test, target_column=None)\n",
    "print(re5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6d669637-b90d-4bc0-b55e-f1aa7cb65cd3",
   "metadata": {},
   "source": [
    "Predicting DataLoader 0: 100%\n",
    "79/79 [00:02<00:00, 38.83it/s]\n",
    "\n",
    "{'f1_macro': 0.9887477313974592}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a323a55-39f6-4627-afee-f497c3294984",
   "metadata": {},
   "source": [
    "---------\n",
    "# Evaluating the LLMs capabilities when creating image classification code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2bea68-a78b-4264-aee8-04f402632ef8",
   "metadata": {},
   "source": [
    "# **Trial 1**: A custom prompt only tackling  data loading \n",
    "I have an image classification dataset contained in a pandas dataframe.\n",
    "The dataframe is called opticalv1 with columns 'image' and 'label'. 'image' contains the path to the image file and 'label' contains the class label.\n",
    "The dataset contains 394 images. \n",
    "\n",
    "All images are 768px in height, 1024px in width, in RGB mode, and saved as png.\n",
    "Here is the class distribution for the dataset:\n",
    "label\n",
    "0    188\n",
    "3     56\n",
    "2     37\n",
    "1     34\n",
    "\n",
    "Generate me python code to load this dataset into a format that can be directly used by deep learning libraries like pytorch or tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717d8849-a2a7-4dcb-b515-d98f054ff553",
   "metadata": {},
   "source": [
    "## Hermes was evaluated to provide the code to load the file-paths in the DataFrame into tensors\n",
    "```python\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "# Load the dataframe:\n",
    "df = train_few20\n",
    "# Define a function to preprocess each image:\n",
    "def preprocess(image):\n",
    "    # load the image from file\n",
    "    img = Image.open(image).convert('RGB')\n",
    "    \n",
    "    # resize the image to 256x256 pixels (if necessary)\n",
    "    if img.width != 768 or img.height != 1024:\n",
    "        img = img.resize((256, 256))#, Image.ANTIALIAS)\n",
    "    \n",
    "    # normalize the pixel values to be between -1 and 1 (if necessary)\n",
    "    if img.mode == 'L':\n",
    "        img = img.convert('RGB')\n",
    "    elif img.mode != 'RGB':\n",
    "        img = img.convert('RGB', colorspace='lab2rgb_reflect')\n",
    "\n",
    "    # normalize the normalize the pixel values to be between -1 and 1 (if necessary)\n",
    "\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "    std = torch.tensor([0.229, 0.224, 0.225])\n",
    "\n",
    "    img_tensor = Image.fromarray(img.resize((224, 224)))#, Image.ANTIALIAS))\n",
    "    normalized_img = (img_tensor / 255.0) * std + mean\n",
    "\n",
    "    # return the preprocessed image as a PyTorch tensor\n",
    "    return torch.from_numpy(normalized_img.as_inplace().astype('float32'))\n",
    "\n",
    "#Applying this function to each row of the dataframe will create a new column called 'image_tensor' that contains the preprocessed images in PyTorch format:\n",
    "\n",
    "df['image_tensor'] = df['image'].apply(preprocess)\n",
    "# Convert the dataset into a torch.utils.data.Dataset object to use\n",
    "```\n",
    "\n",
    "#### there are some small confusions in the code an the operations and conversions between data types (torch/np/PIL) are not entirely correct "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aebc4bb-cd44-4ad6-af9d-97ea40bc156a",
   "metadata": {},
   "source": [
    "# **Trial 2**: A custom prompt describing the situation where data has been converted into a numpy array\n",
    "I have an image classification dataset contained in two numpy arrays X and y. X is of shape (394, 768, 1024, 3) and y is of shape (394,) The dataset thus contains 394 images. All images are 768px in height, 1024px in width, in RGB mode, and saved as png. Here is the class distribution for y:\n",
    "\n",
    "0 188 3 56 2 37 1 34\n",
    "\n",
    "Generate me python code to create and train a neural network for this data. Annotate appropriately for understanding and further use. \n",
    "\n",
    "## Hermes was able to provide a fitting answer in two parts \n",
    "First answer:\n",
    "\n",
    "\n",
    "```python\n",
    "    import numpy as np\n",
    "    from tensorflow import keras\n",
    "    # Load the data into NumPy arrays.\n",
    "    X = np.array(x)  # shape (394, 768, 1024, 3)\n",
    "    y = np.array(y)  # shape (394,)\n",
    "    #Class labels are one-hot encoded using scikit-learn's LabelEncoder class.\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    y_encoded = y_encoded.reshape(-1, 1)\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    y_encoded = onehot_encoder.fit_transform(y_encoded)  # Then, one-hot encode\n",
    "\n",
    "\n",
    "\n",
    "    #Create a Keras Sequential model with two convolutional layers and a softmax output layer.\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(768,1024, 3)),\n",
    "        keras.layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "```\n",
    "\n",
    "Prompt 2: \n",
    "\n",
    "Continue building the network and evaluate it on the test data.\n",
    "\n",
    "Answer 2:\n",
    "```python\n",
    "        # Add a second convolutional layer with 64 filters, followed by another max pooling layer.\n",
    "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        keras.layers.MaxPooling2D((2, 2)),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dropout(.5),\n",
    "        keras.layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "        \n",
    "    #Compile the model with binary cross-entropy loss and Adam optimizer.\n",
    "    model.compile(optimizer=keras.optimizers.Adam(),\n",
    "                  loss=keras.losses.BinaryCrossentropy(),\n",
    "                  loss=keras.losses.CategoricalCrossentropy(), \n",
    "                  metrics=[keras.metrics.Accuracy(), f1])\n",
    "    #Fit the model on the data using epochs parameter to specify number of iterations over the dataset.\n",
    "    model.fit(X, y_encoded, epochs=50)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y_test = le.fit_transform(y_test)\n",
    "    y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    y_test = onehot_encoder.fit_transform(y_test)\n",
    "    \n",
    "    print(model.evaluate(X_test, y_test))\n",
    "```\n",
    "\n",
    "### Apart from the use of a 3-neuron output and binary cross-entropy, this network is appropriate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c30bcd-103b-4e85-b0fc-49eeb7690371",
   "metadata": {},
   "source": [
    "## Applying the LLMs answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "353bf586-c82c-4270-9596-23bde5f7e59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_few5, y_train_few5 = DataLoader.imageDataFrameToNumpyXy(train_few5)\n",
    "X_train_few20, y_train_few20 = DataLoader.imageDataFrameToNumpyXy(train_few20)\n",
    "\n",
    "X_test, y_test = DataLoader.imageDataFrameToNumpyXy(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f46cf0d-9451-48d5-81ec-d6955f0207be",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = tf.keras.metrics.F1Score(\n",
    "        average='macro', threshold=None, name='f1_score', dtype=None\n",
    "    )\n",
    "\n",
    "def hermes_cnn_numpy(X, y, X_test, y_test):\n",
    "    import numpy as np\n",
    "    from tensorflow import keras\n",
    "    # Load the data into NumPy arrays.\n",
    "    #X = np.array(x)  # shape (394, 768, 1024, 3)\n",
    "    #y = np.array(y)  # shape (394,)\n",
    "    #Class labels are one-hot encoded using scikit-learn's LabelEncoder class.\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    y_encoded = y_encoded.reshape(-1, 1)\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    y_encoded = onehot_encoder.fit_transform(y_encoded)  # Then, one-hot encode\n",
    "\n",
    "\n",
    "\n",
    "    #Create a Keras Sequential model with two convolutional layers and a softmax output layer.\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(768,1024, 3)),\n",
    "        keras.layers.MaxPooling2D((2, 2)),\n",
    "        #################################################### Answers split here\n",
    "        # Add a second convolutional layer with 64 filters, followed by another max pooling layer.\n",
    "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        keras.layers.MaxPooling2D((2, 2)),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dropout(.5),\n",
    "        keras.layers.Dense(4, activation='softmax')     # EDITED   was 3 neurons\n",
    "    ])\n",
    "        \n",
    "    #Compile the model with binary cross-entropy loss and Adam optimizer.\n",
    "    model.compile(optimizer=keras.optimizers.Adam(),\n",
    "                  #loss=keras.losses.BinaryCrossentropy(),  # EDITED was BinaryCrossentropy\n",
    "                  loss=keras.losses.CategoricalCrossentropy(), \n",
    "                  metrics=[keras.metrics.Accuracy(), f1])\n",
    "    #Fit the model on the data using epochs parameter to specify number of iterations over the dataset.\n",
    "    model.fit(X, y_encoded, epochs=25)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y_test = le.fit_transform(y_test)\n",
    "    y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    y_test = onehot_encoder.fit_transform(y_test)\n",
    "    \n",
    "    print(model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e4dde65-fa07-4f70-8f8d-a9cab51687f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/automl/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step - loss: 32.6969 - accuracy: 0.1000 - f1_score: 0.4067\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 42442.2617 - accuracy: 0.6250 - f1_score: 0.1000\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 40871.6914 - accuracy: 0.6000 - f1_score: 0.0870\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 11907.4951 - accuracy: 0.6750 - f1_score: 0.2902\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 7222.6016 - accuracy: 0.7250 - f1_score: 0.4561\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 9053.6348 - accuracy: 0.7000 - f1_score: 0.3746\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 5527.4897 - accuracy: 0.7500 - f1_score: 0.4280\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 1637.0824 - accuracy: 0.7500 - f1_score: 0.5016\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 1283.6139 - accuracy: 0.8375 - f1_score: 0.6619\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 670.2962 - accuracy: 0.7875 - f1_score: 0.5179\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 610.4679 - accuracy: 0.7500 - f1_score: 0.5401\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 170.8862 - accuracy: 0.8375 - f1_score: 0.6958\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 17.2924 - accuracy: 0.9625 - f1_score: 0.9495\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 167.5108 - accuracy: 0.8375 - f1_score: 0.6748\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0000e+00 - accuracy: 0.9375 - f1_score: 1.0000\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 54.1617 - accuracy: 0.7375 - f1_score: 0.8495\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 6.0706 - accuracy: 0.7250 - f1_score: 0.7292\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 18.4888 - accuracy: 0.6875 - f1_score: 0.7550\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 1.6689e-07 - accuracy: 0.7625 - f1_score: 1.0000\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0623 - accuracy: 0.7750 - f1_score: 0.9495\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.3251 - accuracy: 0.7625 - f1_score: 0.9495\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0104 - accuracy: 0.7250 - f1_score: 1.0000\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 2.3603e-06 - accuracy: 0.8000 - f1_score: 1.0000\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.0487 - accuracy: 0.7500 - f1_score: 0.9495\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 6.3832e-06 - accuracy: 0.7375 - f1_score: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/automl/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 59ms/step - loss: 82.2538 - accuracy: 0.7563 - f1_score: 0.4254\n",
      "[82.2537612915039, 0.7563291192054749, 0.4253558814525604]\n"
     ]
    }
   ],
   "source": [
    "hermes_cnn_numpy(X_train_few5, y_train_few5, X_test, y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8396d22b-abfd-4ba2-b469-07a68b30a8d5",
   "metadata": {},
   "source": [
    "Epoch 1/25\n",
    "\n",
    "/usr/local/automl/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
    "  warnings.warn(\n",
    "\n",
    "1/1 [==============================] - 1s 1s/step - loss: 73.0862 - accuracy: 0.4000 - f1_score: 0.1429\n",
    "Epoch 2/25\n",
    "1/1 [==============================] - 0s 165ms/step - loss: 60171.3984 - accuracy: 0.6500 - f1_score: 0.2020\n",
    "Epoch 3/25\n",
    "1/1 [==============================] - 0s 164ms/step - loss: 99283.6562 - accuracy: 0.6750 - f1_score: 0.2386\n",
    "Epoch 4/25\n",
    "1/1 [==============================] - 0s 159ms/step - loss: 30925.0566 - accuracy: 0.7250 - f1_score: 0.3917\n",
    "Epoch 5/25\n",
    "1/1 [==============================] - 0s 159ms/step - loss: 20344.6348 - accuracy: 0.7000 - f1_score: 0.3766\n",
    "Epoch 6/25\n",
    "1/1 [==============================] - 0s 159ms/step - loss: 17082.1074 - accuracy: 0.7250 - f1_score: 0.4113\n",
    "Epoch 7/25\n",
    "1/1 [==============================] - 0s 159ms/step - loss: 10202.9863 - accuracy: 0.6750 - f1_score: 0.2905\n",
    "Epoch 8/25\n",
    "1/1 [==============================] - 0s 158ms/step - loss: 8315.7217 - accuracy: 0.6500 - f1_score: 0.2396\n",
    "Epoch 9/25\n",
    "1/1 [==============================] - 0s 161ms/step - loss: 2217.1375 - accuracy: 0.7750 - f1_score: 0.5167\n",
    "Epoch 10/25\n",
    "1/1 [==============================] - 0s 159ms/step - loss: 1920.6133 - accuracy: 0.6750 - f1_score: 0.3671\n",
    "Epoch 11/25\n",
    "1/1 [==============================] - 0s 158ms/step - loss: 1819.7881 - accuracy: 0.7750 - f1_score: 0.5512\n",
    "Epoch 12/25\n",
    "1/1 [==============================] - 0s 165ms/step - loss: 822.0021 - accuracy: 0.8500 - f1_score: 0.6677\n",
    "Epoch 13/25\n",
    "1/1 [==============================] - 0s 157ms/step - loss: 726.7164 - accuracy: 0.8500 - f1_score: 0.6866\n",
    "Epoch 14/25\n",
    "1/1 [==============================] - 0s 158ms/step - loss: 74.6777 - accuracy: 0.9500 - f1_score: 0.9000\n",
    "Epoch 15/25\n",
    "1/1 [==============================] - 0s 155ms/step - loss: 131.6446 - accuracy: 0.8375 - f1_score: 0.6970\n",
    "Epoch 16/25\n",
    "1/1 [==============================] - 0s 158ms/step - loss: 84.0474 - accuracy: 0.8750 - f1_score: 0.7495\n",
    "Epoch 17/25\n",
    "1/1 [==============================] - 0s 156ms/step - loss: 23.4668 - accuracy: 0.9375 - f1_score: 0.8995\n",
    "Epoch 18/25\n",
    "1/1 [==============================] - 0s 158ms/step - loss: 52.9563 - accuracy: 0.8125 - f1_score: 0.7980\n",
    "Epoch 19/25\n",
    "1/1 [==============================] - 0s 157ms/step - loss: 156.8609 - accuracy: 0.8500 - f1_score: 0.6162\n",
    "Epoch 20/25\n",
    "1/1 [==============================] - 0s 159ms/step - loss: 30.7261 - accuracy: 0.7875 - f1_score: 0.7386\n",
    "Epoch 21/25\n",
    "1/1 [==============================] - 0s 159ms/step - loss: 61.9324 - accuracy: 0.8500 - f1_score: 0.7412\n",
    "Epoch 22/25\n",
    "1/1 [==============================] - 0s 158ms/step - loss: 13.3266 - accuracy: 0.8000 - f1_score: 0.7917\n",
    "Epoch 23/25\n",
    "1/1 [==============================] - 0s 158ms/step - loss: 9.2610 - accuracy: 0.8125 - f1_score: 0.8958\n",
    "Epoch 24/25\n",
    "1/1 [==============================] - 0s 158ms/step - loss: 2.0494 - accuracy: 0.7000 - f1_score: 0.8995\n",
    "Epoch 25/25\n",
    "1/1 [==============================] - 0s 158ms/step - loss: 0.8388 - accuracy: 0.5875 - f1_score: 0.9495\n",
    "\n",
    "/usr/local/automl/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
    "  warnings.warn(\n",
    "\n",
    "3/3 [==============================] - 0s 56ms/step - loss: 26.9248 - accuracy: 0.6835 - f1_score: 0.4976\n",
    "[26.9247989654541, 0.6835442781448364, 0.49764764308929443]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03333d88-6bf9-4362-8696-aea961a834b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/automl/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "3/3 [==============================] - 2s 193ms/step - loss: 32456.3008 - accuracy: 0.4313 - f1_score: 0.1681\n",
      "Epoch 2/25\n",
      "3/3 [==============================] - 1s 193ms/step - loss: 22263.7129 - accuracy: 0.6812 - f1_score: 0.3132\n",
      "Epoch 3/25\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 5062.3013 - accuracy: 0.6844 - f1_score: 0.3382\n",
      "Epoch 4/25\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 1135.6100 - accuracy: 0.7531 - f1_score: 0.4948\n",
      "Epoch 5/25\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 440.9905 - accuracy: 0.7156 - f1_score: 0.4606\n",
      "Epoch 6/25\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 52.7818 - accuracy: 0.7094 - f1_score: 0.6434\n",
      "Epoch 7/25\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 14.7284 - accuracy: 0.5562 - f1_score: 0.6704\n",
      "Epoch 8/25\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 12.1084 - accuracy: 0.4750 - f1_score: 0.6200\n",
      "Epoch 9/25\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 4.3462 - accuracy: 0.4437 - f1_score: 0.6747\n",
      "Epoch 10/25\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 1.0845 - accuracy: 0.4563 - f1_score: 0.7265\n",
      "Epoch 11/25\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 0.4861 - accuracy: 0.4469 - f1_score: 0.7757\n",
      "Epoch 12/25\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 0.3897 - accuracy: 0.4625 - f1_score: 0.8850\n",
      "Epoch 13/25\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 1.9030 - accuracy: 0.4250 - f1_score: 0.9498\n",
      "Epoch 14/25\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 3.4839 - accuracy: 0.4031 - f1_score: 0.8312\n",
      "Epoch 15/25\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 1.4734 - accuracy: 0.4125 - f1_score: 0.8870\n",
      "Epoch 16/25\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 1.1822 - accuracy: 0.4375 - f1_score: 0.9380\n",
      "Epoch 17/25\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 0.2981 - accuracy: 0.4313 - f1_score: 0.9484\n",
      "Epoch 18/25\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 0.3258 - accuracy: 0.4563 - f1_score: 0.9630\n",
      "Epoch 19/25\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 0.3137 - accuracy: 0.4344 - f1_score: 0.9750\n",
      "Epoch 20/25\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 0.3685 - accuracy: 0.4187 - f1_score: 0.9625\n",
      "Epoch 21/25\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 0.2678 - accuracy: 0.4500 - f1_score: 0.9750\n",
      "Epoch 22/25\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 0.2506 - accuracy: 0.4313 - f1_score: 0.9623\n",
      "Epoch 23/25\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 0.2878 - accuracy: 0.4406 - f1_score: 0.9875\n",
      "Epoch 24/25\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 0.2249 - accuracy: 0.4437 - f1_score: 0.9875\n",
      "Epoch 25/25\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 0.1953 - accuracy: 0.4437 - f1_score: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/automl/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f8193cfe700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f8193cfe700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 58ms/step - loss: 0.9672 - accuracy: 0.3133 - f1_score: 0.5549\n",
      "[0.9672031402587891, 0.31329113245010376, 0.554914653301239]\n"
     ]
    }
   ],
   "source": [
    "hermes_cnn_numpy(X_train_few20, y_train_few20, X_test, y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1caa6302-46ac-4a1f-b184-114575021967",
   "metadata": {},
   "source": [
    "Epoch 1/25\n",
    "3/3 [==============================] - 2s 193ms/step - loss: 32456.3008 - accuracy: 0.4313 - f1_score: 0.1681\n",
    "Epoch 2/25\n",
    "3/3 [==============================] - 1s 193ms/step - loss: 22263.7129 - accuracy: 0.6812 - f1_score: 0.3132\n",
    "Epoch 3/25\n",
    "3/3 [==============================] - 1s 213ms/step - loss: 5062.3013 - accuracy: 0.6844 - f1_score: 0.3382\n",
    "Epoch 4/25\n",
    "3/3 [==============================] - 1s 204ms/step - loss: 1135.6100 - accuracy: 0.7531 - f1_score: 0.4948\n",
    "Epoch 5/25\n",
    "3/3 [==============================] - 1s 211ms/step - loss: 440.9905 - accuracy: 0.7156 - f1_score: 0.4606\n",
    "Epoch 6/25\n",
    "3/3 [==============================] - 1s 209ms/step - loss: 52.7818 - accuracy: 0.7094 - f1_score: 0.6434\n",
    "Epoch 7/25\n",
    "3/3 [==============================] - 1s 210ms/step - loss: 14.7284 - accuracy: 0.5562 - f1_score: 0.6704\n",
    "Epoch 8/25\n",
    "3/3 [==============================] - 1s 211ms/step - loss: 12.1084 - accuracy: 0.4750 - f1_score: 0.6200\n",
    "Epoch 9/25\n",
    "3/3 [==============================] - 1s 213ms/step - loss: 4.3462 - accuracy: 0.4437 - f1_score: 0.6747\n",
    "Epoch 10/25\n",
    "3/3 [==============================] - 1s 211ms/step - loss: 1.0845 - accuracy: 0.4563 - f1_score: 0.7265\n",
    "Epoch 11/25\n",
    "3/3 [==============================] - 1s 213ms/step - loss: 0.4861 - accuracy: 0.4469 - f1_score: 0.7757\n",
    "Epoch 12/25\n",
    "3/3 [==============================] - 1s 213ms/step - loss: 0.3897 - accuracy: 0.4625 - f1_score: 0.8850\n",
    "Epoch 13/25\n",
    "3/3 [==============================] - 1s 210ms/step - loss: 1.9030 - accuracy: 0.4250 - f1_score: 0.9498\n",
    "Epoch 14/25\n",
    "3/3 [==============================] - 1s 211ms/step - loss: 3.4839 - accuracy: 0.4031 - f1_score: 0.8312\n",
    "Epoch 15/25\n",
    "3/3 [==============================] - 1s 210ms/step - loss: 1.4734 - accuracy: 0.4125 - f1_score: 0.8870\n",
    "Epoch 16/25\n",
    "3/3 [==============================] - 1s 212ms/step - loss: 1.1822 - accuracy: 0.4375 - f1_score: 0.9380\n",
    "Epoch 17/25\n",
    "3/3 [==============================] - 1s 211ms/step - loss: 0.2981 - accuracy: 0.4313 - f1_score: 0.9484\n",
    "Epoch 18/25\n",
    "3/3 [==============================] - 1s 205ms/step - loss: 0.3258 - accuracy: 0.4563 - f1_score: 0.9630\n",
    "Epoch 19/25\n",
    "3/3 [==============================] - 1s 210ms/step - loss: 0.3137 - accuracy: 0.4344 - f1_score: 0.9750\n",
    "Epoch 20/25\n",
    "3/3 [==============================] - 1s 210ms/step - loss: 0.3685 - accuracy: 0.4187 - f1_score: 0.9625\n",
    "Epoch 21/25\n",
    "3/3 [==============================] - 1s 211ms/step - loss: 0.2678 - accuracy: 0.4500 - f1_score: 0.9750\n",
    "Epoch 22/25\n",
    "3/3 [==============================] - 1s 210ms/step - loss: 0.2506 - accuracy: 0.4313 - f1_score: 0.9623\n",
    "Epoch 23/25\n",
    "3/3 [==============================] - 1s 210ms/step - loss: 0.2878 - accuracy: 0.4406 - f1_score: 0.9875\n",
    "Epoch 24/25\n",
    "3/3 [==============================] - 1s 204ms/step - loss: 0.2249 - accuracy: 0.4437 - f1_score: 0.9875\n",
    "Epoch 25/25\n",
    "3/3 [==============================] - 1s 226ms/step - loss: 0.1953 - accuracy: 0.4437 - f1_score: 1.0000\n",
    "\n",
    "/usr/local/automl/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
    "  warnings.warn(\n",
    "\n",
    "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f8193cfe700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
    "\n",
    "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f8193cfe700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
    "\n",
    "3/3 [==============================] - 0s 58ms/step - loss: 0.9672 - accuracy: 0.3133 - f1_score: 0.5549\n",
    "[0.9672031402587891, 0.31329113245010376, 0.554914653301239]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python automl",
   "language": "python",
   "name": "automl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
